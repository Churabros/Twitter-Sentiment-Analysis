























import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns
from wordcloud import WordCloud
from collections import Counter
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from sklearn.decomposition import PCA
import nltk
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import RandomizedSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings("ignore")

nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')



# df = pd.read_csv('/content/judge-1377884607_tweet_product_company.csv', encoding='latin-1')


df = pd.read_csv('./Data/judge-1377884607_tweet_product_company.csv', encoding='latin-1')


#df = pd.read_csv('judge-1377884607_tweet_product_company.csv', encoding='latin-1')


df.head()


# renaming the columns for easier workflow
df.rename(columns={'tweet_text': 'tweet', 'emotion_in_tweet_is_directed_at': 'product', 'is_there_an_emotion_directed_at_a_brand_or_product': 'sentiment', }, inplace=True)
df.head()


df.info()


# removing the row from sentiment column where a tweet is missing
df = df.dropna(subset=['tweet'])
df.info()


df['product'].isna().sum()


# filling in the missing values
df['product'].fillna('Missing')
df.info()


df['sentiment'].value_counts()





# renaming sentiment labels
df['sentiment'] = df['sentiment'].replace({'No emotion toward brand or product': 'neutral',
                                           'Positive emotion': 'positive',
                                           'Negative emotion': 'negative',
                                           'I can\'t tell': 'can\'t tell'})

# filtering out the can't tell sentiments
df = df[df['sentiment'] != "can't tell"]

df['sentiment'].value_counts()





def clean_text(text):
    # checking if text is a string before applying regex
    if isinstance(text, str):
        # removing mentions (@username)
        text = re.sub(r'@\w+', '', text)

        # removing URLs
        text = re.sub(r'http\S+|www\S+|https\S+', '', text)

        # removing hashtags
        text = re.sub(r'#\w+', '', text)

        # removing extra whitespaces
        text = re.sub(r'\s+', ' ', text).strip()

        # removing emojis
        text = re.sub(r'[^\x00-\x7F]+', '', text)

        # removing special characters and numbers
        text = re.sub(r'[^a-zA-Z\s]', '', text)

        # removing punctuation
        text = re.sub(r'[^\w\s]', '', text)

        # converting to lowercase
        text = text.lower()
    return text

# applying cleaning to the dataset
df['cleaned_text'] = df['tweet'].apply(clean_text)


df.info()


df.head()





# initializing stopwords and lemmatizer
stop_words = set(stopwords.words('english'))
lem = WordNetLemmatizer()

# function to do tokenization, stopword removal, and lemmatization
def process_text(text):
    if isinstance(text, str):
        # tokenizing the text
        tokens = word_tokenize(text)

        # removing stopwords
        filtered_tokens = []
        for token in tokens:
          if token not in stop_words:
            filtered_tokens.append(token)

        # lemmatization
        lem_tokens = []
        for token in filtered_tokens:
          lem_tokens.append(lem.lemmatize(token))

        # joining tokens back to a single string
        return ' '.join(lem_tokens)
    return text

# applying the function to the cleaned text
df['processed_text'] = df['cleaned_text'].apply(process_text)


df.head()











tfidf = TfidfVectorizer(max_features=5000, stop_words='english')

# Fit and transform the processed_text column
X = tfidf.fit_transform(df['processed_text'])

# converting the resulting sparse matrix to a DataFrame for easier inspection
X_tfidf = pd.DataFrame(X.toarray(), columns=tfidf.get_feature_names_out())

X_tfidf






# Apply PCA to reduce the dimensionality to 2 components
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_tfidf)

# Plot the PCA result with a scatter plot
plt.figure(figsize=(8, 6))

# Map sentiment labels to color for visualization
sentiment_colors = {
    'negative': 'red',
    'positive': 'green',
    'neutral': 'blue'
}
colors = df['sentiment'].map(sentiment_colors)

# Scatter plot with PCA components
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=colors)
plt.title('PCA Visualization of Tweets (Positive, Negative, Neutral)')
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')
plt.show()





sentiment_counts = df['sentiment'].value_counts()
sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values)
plt.title('Distribution of Sentiment')
plt.xlabel('Sentiment')
plt.ylabel('Count')
plt.show()








plt.figure(figsize=(12, 6))
sns.countplot(data=df, x='product', hue='sentiment')
plt.xticks(rotation=45, ha='right')
plt.title('Sentiment Distribution by Product')
plt.xlabel('Product')
plt.ylabel('Count')
plt.legend(title='Sentiment')
plt.subplots_adjust(bottom=0.2)
plt.tight_layout()
plt.show()








df['tweet_length'] = df['tweet'].apply(lambda x: len(x.split()))
plt.figure(figsize=(10, 6))
sns.boxplot(x='sentiment', y='tweet_length', data=df)
plt.title('Average Length of Tweets by Sentiment')
plt.xlabel('Sentiment')
plt.ylabel('Tweet Length (number of words)')
plt.show()








from collections import Counter

all_words = ' '.join(df['processed_text']).split()
word_counts = Counter(all_words)
common_words = word_counts.most_common(10)  # top 10 most common words
# common_words

# creating a DataFrame for better visualization
common_words_df = pd.DataFrame(common_words, columns=['Word', 'Count'])
sns.barplot(x='Count', y='Word', data=common_words_df)
plt.title('Top 10 Commonly Used Words')
plt.show()








# combining all processed text into a single string
all_processed_text = ' '.join(df['processed_text'])

# counting word frequencies
word_freq = Counter(all_processed_text.split())

# creating the word cloud from frequencies
wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_freq)

# plotting
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()














X = X_tfidf
y = df['sentiment']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# print("Training set size:", X_train.shape)
# print("Test set size:", X_test.shape)



y.value_counts()











# Initialize the Logistic Regression model
baseline_model = LogisticRegression(random_state=42)

# Fit the model on the training data
baseline_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred_baseline = baseline_model.predict(X_test)

# evaluating using F1-score
baseline_f1_score = f1_score(y_test, y_pred_baseline, average='weighted')
print("Baseline Model f1 score:", baseline_f1_score)
print()

# plotting the confusion matrix
cm = confusion_matrix(y_test, y_pred_baseline, labels=['negative', 'neutral', 'positive'])

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=['negative', 'neutral', 'positive'], yticklabels=['negative', 'neutral', 'positive'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix for Baseline Logistic Regression Model')
plt.show()








# Define the hyperparameter distribution, including class_weight
param_distributions = {
    'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100],
    'logisticregression__solver': ['liblinear', 'lbfgs', 'saga'],
    'logisticregression__class_weight': ['balanced', None],
    'logisticregression__penalty': ['l1', 'l2'],
    'logisticregression__max_iter': [100, 200, 300]
}

# Create a pipeline with Logistic Regression
pipeline = Pipeline([
    ('logisticregression', LogisticRegression())
])

# Initialize Randomized Search
random_search = RandomizedSearchCV(pipeline,
                                   param_distributions,
                                   scoring='f1_weighted',
                                   n_iter=10,
                                   cv=5,
                                   random_state=42,
                                   n_jobs=-1)

# Fit the model on the training data
random_search.fit(X_train, y_train)

# Get the best parameters
best_params = random_search.best_params_
print("Best Hyperparameters:", best_params)
print()

# Predict using the best model
best_model = random_search.best_estimator_
y_pred_tuned = best_model.predict(X_test)

# Evaluate the tuned model
best_f1_score = f1_score(y_test, y_pred_tuned, average='weighted')
print("Improved Model f1 score:", best_f1_score)
print()

# Confusion Matrix
cm_best = confusion_matrix(y_test, y_pred_tuned, labels=['negative', 'neutral', 'positive'])

# Plotting the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm_best, annot=True, fmt="d", cmap="Blues",
            xticklabels=['negative', 'neutral', 'positive'],
            yticklabels=['negative', 'neutral', 'positive'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix for Improved Logistic Regression Model with Pipeline')
plt.show()








# Define the hyperparameter distribution for Random Forest
param_distributions_rf = {
    'randomforestclassifier__n_estimators': [10, 50, 100, 200],
    'randomforestclassifier__min_samples_split': [2, 5, 10],
    'randomforestclassifier__min_samples_leaf': [1, 2, 4],
    'randomforestclassifier__max_features': ['sqrt', 'log2'],
    'randomforestclassifier__max_depth': [None, 10, 20, 30, 40, 50],
    'randomforestclassifier__class_weight': ['balanced', None],
}

# Create a pipeline with Random Forest
pipeline_rf = Pipeline([
    ('randomforestclassifier', RandomForestClassifier(random_state=42))
])

# Initialize Randomized Search
random_search_rf = RandomizedSearchCV(pipeline_rf,
                                       param_distributions_rf,
                                       scoring='f1_weighted',
                                       n_iter=10,
                                       cv=5,
                                       random_state=42,
                                      n_jobs=-1)

# Fit the model on the training data
random_search_rf.fit(X_train, y_train)

# Get the best parameters
best_params_rf = random_search_rf.best_params_
print("Best Hyperparameters:", best_params_rf)
print()

# Predict using the best model
best_model_rf = random_search_rf.best_estimator_
y_pred_rf_tuned = best_model_rf.predict(X_test)

# Evaluate the tuned model
best_f1_score_rf = f1_score(y_test, y_pred_rf_tuned, average='weighted')
print("Tuned Random Forest Model f1 score:", best_f1_score_rf)
print()

# Confusion Matrix
cm_best_rf = confusion_matrix(y_test, y_pred_rf_tuned, labels=['negative', 'neutral', 'positive'])

# Plotting the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm_best_rf, annot=True, fmt="d", cmap="Blues",
            xticklabels=['negative', 'neutral', 'positive'],
            yticklabels=['negative', 'neutral', 'positive'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix for Tuned Random Forest Model with Pipeline')
plt.show()








!pip install shap


import shap

# Initialize and fit the Random Forest model with best hyperparameters
rf_model = RandomForestClassifier(n_estimators=200,
                                  min_samples_split=10,
                                  min_samples_leaf=2,
                                  max_features = 'sqrt',
                                  max_depth = None,
                                  random_state = 42,
                                  class_weight = 'balanced',
                                  n_jobs=-1
                                  )

rf_model.fit(X_train, y_train)

# Create a SHAP Explainer
explainer = shap.Explainer(rf_model, X_train)

# Calculate SHAP values for the test dataset
shap_values = explainer(X_test)

# Create a summary plot of SHAP values
shap.summary_plot(shap_values[:,:,1], X_test, plot_type="bar")











from sklearn.ensemble import VotingClassifier

# Tuned Logistic Regression model
log_reg = LogisticRegression(
    C=1, solver='liblinear', penalty='l2', max_iter=100, class_weight='balanced', random_state=42
)

# Tuned Random Forest model
rf_model = RandomForestClassifier(
    n_estimators=200, min_samples_split=10, min_samples_leaf=2, max_features='sqrt',
    max_depth=None, class_weight='balanced', random_state=42, n_jobs=-1
)

# Create an ensemble using VotingClassifier with soft voting (averaging probabilities)
ensemble_model = VotingClassifier(
    estimators=[('log_reg', log_reg), ('rf_model', rf_model)], voting='soft'
)

# Train the ensemble model
ensemble_model.fit(X_train, y_train)

# Predict using the ensemble model
y_pred_ensemble = ensemble_model.predict(X_test)

# Evaluate using f1_score or other metrics
ensemble_f1_score = f1_score(y_test, y_pred_ensemble, average='weighted')
print("Ensemble Model f1 score:", ensemble_f1_score)
print()

# Confusion Matrix
cm_ensemble = confusion_matrix(y_test, y_pred_ensemble, labels=['negative', 'neutral', 'positive'])

# Plotting the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm_ensemble, annot=True, fmt="d", cmap="Blues",
            xticklabels=['negative', 'neutral', 'positive'],
            yticklabels=['negative', 'neutral', 'positive'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix for Ensemble Model (Logistic Regression + Random Forest)')
plt.show()











# Define the TfidfVectorizer
vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Encode the labels
encoder = LabelEncoder()
y_train_encoded = encoder.fit_transform(y_train)
y_test_encoded = encoder.transform(y_test)

# Define the Neural Network model
model = Sequential()

# Input layer and first hidden layer
model.add(Dense(128, input_shape=(X_train_tfidf.shape[1],), activation='relu'))
model.add(Dropout(0.2))

# Second hidden layer
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.2))

# Third hidden layer
model.add(Dense(32, activation='relu'))

# Output layer (3 classes: positive, neutral, negative)
model.add(Dense(3, activation='softmax'))

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(X_train_tfidf.toarray(), y_train_encoded, epochs=5, batch_size=64, validation_split=0.2, verbose=1)

# Evaluate the model on test data
y_pred_probs = model.predict(X_test_tfidf.toarray())
y_pred = np.argmax(y_pred_probs, axis=1)

# F1-score
nn_f1_score = f1_score(y_test_encoded, y_pred[:len(y_test_encoded)], average='weighted')
print("Neural Network Model f1 score:", nn_f1_score)
print()

# Confusion Matrix
cm_nn = confusion_matrix(y_test_encoded, y_pred[:len(y_test_encoded)])

# Plotting the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm_nn, annot=True, fmt="d", cmap="Blues",
            xticklabels=encoder.classes_,
            yticklabels=encoder.classes_)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix for Neural Network Model')
plt.show()


print(cm_nn)















